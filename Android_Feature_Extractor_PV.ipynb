{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978d0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from time import time\n",
    "from random import shuffle\n",
    "import gensim\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "tqdm.pandas(desc=\"progress-bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ddf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FilterReport ( static_analysis ) :\n",
    "    report = str(static_analysis)\n",
    "    report = report.split(' ')\n",
    "    noise = \"{}()[],':\\\\\" + '\"'\n",
    "    filtered_report = []\n",
    "    for token in report :\n",
    "        refined = token\n",
    "        refined = refined.replace(\"\\n\", '')\n",
    "        for n in noise :\n",
    "            refined = refined.replace(n, '')\n",
    "        filtered_report.append(refined)\n",
    "    return filtered_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fae3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadRawDataset ( directory ) :\n",
    "    malicious_apps_folder = directory + '/malware'\n",
    "    benign_apps_folder = directory + '/benign'\n",
    "    \n",
    "    report_label_pairs = []\n",
    "    \n",
    "    for file_name in [file for file in os.listdir(malicious_apps_folder) if file.endswith('.json')] :\n",
    "        with open(malicious_apps_folder + '/' + file_name) as json_file :\n",
    "            report = json.load(json_file)\n",
    "            filtered_report = FilterReport(report)\n",
    "            report_label_pairs.append((filtered_report, 1))\n",
    "    \n",
    "    for file_name in [file for file in os.listdir(benign_apps_folder) if file.endswith('.json')] :\n",
    "        with open(benign_apps_folder + '/' + file_name) as json_file :\n",
    "            report = json.load(json_file)\n",
    "            filtered_report = FilterReport(report)\n",
    "            report_label_pairs.append((filtered_report, 0))\n",
    "    \n",
    "    return report_label_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0636b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TagRawReportData ( raw_dataset ) :\n",
    "    labeled = []\n",
    "    for idx_label , (word_vector, is_malicious) in enumerate(raw_dataset):\n",
    "        label = str(is_malicious) + '_' + str(idx_label)\n",
    "        labeled.append(TaggedDocument(word_vector, [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f85414",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def CreateAndTrainPVDMModel ( labelled_raw_data , pvdm_vector_size = 300 ) :\n",
    "    PVDM_MODEL = Doc2Vec(dm=0, vector_size=pvdm_vector_size, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "    PVDM_MODEL.build_vocab([w for w in tqdm(labelled_raw_data)])\n",
    "    \n",
    "    for epoch in range(30) :\n",
    "        PVDM_MODEL.train(utils.shuffle([x for x in tqdm(labelled_raw_data)]), \n",
    "                                       total_examples=len(labelled_raw_data), epochs=1)\n",
    "        PVDM_MODEL.alpha -= 0.002\n",
    "        PVDM_MODEL.min_alpha = PVDM_MODEL.alpha\n",
    "    \n",
    "    return PVDM_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetPVDMVectors ( model , raw_dataset ) :\n",
    "    vectors = []\n",
    "    for idx_label , (word_vector, is_malicious) in enumerate(raw_dataset):\n",
    "        label = str(is_malicious) + '_' + str(idx_label)\n",
    "        vectors.append(model.dv[label])\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa41f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PrepareTrainDataset ( model , raw_dataset ) :\n",
    "    pvdm_vectors = GetPVDMVectors(model, raw_dataset)\n",
    "    train_dataset = []\n",
    "    for idx , (__, is_malicious) in enumerate(raw_dataset):\n",
    "        train_dataset.append((pvdm_vectors[idx], is_malicious))\n",
    "    return train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93708fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeBatches ( train_data , batch_size = 64 ) :\n",
    "    shuffle(train_data)\n",
    "    batches = list()\n",
    "    for start in range(0, len(train_data), batch_size) :\n",
    "        end = start + batch_size\n",
    "        batch, labels = list(zip(*train_data[start:end]))\n",
    "        labels = torch.Tensor(labels).long()\n",
    "        batch = torch.Tensor(batch)\n",
    "        batches.append((batch, labels))\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Android_Feature_Extractor_PVDM ( nn.Module ) :\n",
    "    def __init__ ( self , input_size , feature_size ) :\n",
    "        super(Android_Feature_Extractor_PVDM, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.feature_size = feature_size\n",
    "        \n",
    "        self.drop_features = nn.Dropout ( p = 0.25 )\n",
    "        self.dense_features = nn.Linear ( input_size , feature_size )\n",
    "        \n",
    "        self.drop_classes = nn.Dropout ( p = 0.25 )\n",
    "        self.dense_classes = nn.Linear ( feature_size , 2 )\n",
    "    \n",
    "    def forward ( self , inputs ) :\n",
    "        # inputs : (batch_size, input_size)\n",
    "        dropped_inputs = self.drop_features(inputs)\n",
    "        features = self.dense_features(dropped_inputs)\n",
    "        dropped_features = self.drop_classes(features)\n",
    "        classes = self.dense_classes(dropped_features)\n",
    "        return features, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8952289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainModel ( train_data , total_epochs , learning_rate = 0.01 , batch_size = 64 ) :\n",
    "    global FE_PVDM\n",
    "    optimizer = torch.optim.Adam(FE_PVDM.parameters(), lr = learning_rate)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(total_epochs) :\n",
    "        print('\\n EPOCH {} STARTED '.format(epoch+1))\n",
    "        total_loss = 0.0\n",
    "        batches = MakeBatches(train_data, batch_size)\n",
    "        epoch_start_time = time()\n",
    "        \n",
    "        for step, (batch, labels) in enumerate(batches) :\n",
    "            step_start_time = time()\n",
    "            _, malware_classification = FE_PVDM(batch)\n",
    "            \n",
    "            classification_loss = loss(malware_classification, labels)\n",
    "            total_loss += classification_loss.item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            classification_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            ti = time() - step_start_time\n",
    "            print('    STEP : {:3d} | LOSS : {:.6f} | DUR : {:.4f}'.format(step+1, classification_loss, ti))\n",
    "        \n",
    "        classification_loss = total_loss / len(batches)\n",
    "        ti = time() - epoch_start_time\n",
    "        print(' EPOCH\\'S MEAN LOSS : {:.6f} | DUR : {:.4f}'.format(classification_loss, ti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b390eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RAW_TRAIN_DATA = LoadRawDataset('/Users/nakulaggarwal/Documents/UNBInternship/implementation/data')\n",
    "LABELLED_RAW_DATA = TagRawReportData(RAW_TRAIN_DATA)\n",
    "PVDM_MODEL = CreateAndTrainPVDMModel(LABELLED_RAW_DATA, pvdm_vector_size = 300)\n",
    "TRAIN_DATA = PrepareTrainDataset(PVDM_MODEL, RAW_TRAIN_DATA)\n",
    "FEATURE_LENGTH = 64\n",
    "FE_PVDM = Android_Feature_Extractor_PVDM(300, FEATURE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80296081",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainModel(TRAIN_DATA, 100, 0.001, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2b4b82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
